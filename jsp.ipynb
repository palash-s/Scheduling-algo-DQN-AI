{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [1, 0], [2, 0], [3, 0], [4, 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class JobShop:\n",
    "    # This class is the environment of Job shop problem\n",
    "\n",
    "    bool_generate_random_jssp = None\n",
    "    number_job = None\n",
    "    number_machine = None\n",
    "    number_features = None\n",
    "\n",
    "    # the lower limit of one position of job 's processing time.\n",
    "    time_low = None\n",
    "    # the upper limit of one position of job 's processing time.\n",
    "    time_high = None\n",
    "\n",
    "    # Matrix of processing time, M_processing_time[i,j] is the processing time of job i 's position j.\n",
    "    M_processing_time = None\n",
    "    # Matrix of processing time, M_processing_order[i,j] is the machine restrain of job i 's position j.\n",
    "    M_processing_order = None\n",
    "    M_start_time = None\n",
    "    M_end_time = None\n",
    "    X_schedule_plan = None\n",
    "    schedule_line = None\n",
    "\n",
    "    def __init__(self, number_machine, number_job, time_low, time_high, bool_random):\n",
    "        self.number_job = number_job\n",
    "        self.bool_generate_random_jssp = random\n",
    "        self.number_machine = number_machine\n",
    "        self.time_low = time_low\n",
    "        self.time_high = time_high\n",
    "        self.schedule_line = []\n",
    "        self.GenerateRandomProblem()\n",
    "\n",
    "    def Get_Possible_Job_Position(self):\n",
    "        # ergodic the schedule_line, and return the possible position to produce of jobs\n",
    "\n",
    "        job_position_list = [0 for i in range(self.number_job)]\n",
    "        for job_id, job_position in self.schedule_line:\n",
    "            if job_position < self.number_machine-1:\n",
    "                job_position_list[job_id] = job_position+1\n",
    "            else:\n",
    "                job_position_list[job_id] = -1\n",
    "\n",
    "        return [[i, job_position_list[i]] for i in range(len(job_position_list))]\n",
    "\n",
    "    def Get_Features(self, possible_job_position):\n",
    "        # return the features of current state\n",
    "\n",
    "        featrues = []\n",
    "        for job_id, job_position in possible_job_position:\n",
    "            f_item = self.GetFeature(job_id, job_position)\n",
    "            featrues.append(f_item)\n",
    "\n",
    "        return featrues\n",
    "\n",
    "    def Step(self, action=None):\n",
    "        # be called in main function\n",
    "        # input action and return state score and done\n",
    "        # action: choose a job to process.\n",
    "        # state:\n",
    "\n",
    "        done = False\n",
    "        if action == None:\n",
    "            self.MeasurementAction(self.schedule_line)\n",
    "            possible_pob_position = self.Get_Possible_Job_Position()\n",
    "            state = np.array(self.Get_Features(possible_pob_position))\n",
    "            score = 0\n",
    "        else:\n",
    "\n",
    "            job_position_list = [0 for i in range(self.number_job)]\n",
    "            for job_id, job_position in self.schedule_line:\n",
    "                if job_position < self.number_machine-1:\n",
    "                    job_position_list[job_id] = job_position+1\n",
    "                else:\n",
    "                    job_position_list[job_id] = -1\n",
    "            if job_position_list[action] == -1:\n",
    "                done = True\n",
    "                canchoose = [[i, job_position_list[i]] for i in range(\n",
    "                    self.number_job) if job_position_list[i] != -1]\n",
    "                action = canchoose[0]\n",
    "            else:\n",
    "                action = [action, job_position_list[action]]\n",
    "\n",
    "            self.schedule_line.append(action)\n",
    "            self.MeasurementAction(self.schedule_line)\n",
    "            # self.PlotResult()\n",
    "            score = np.max(self.M_end_time)\n",
    "\n",
    "            possible_pob_position = self.Get_Possible_Job_Position()\n",
    "            state = np.array(self.Get_Features(possible_pob_position))\n",
    "\n",
    "        state = [np.reshape(state[i], (1, 2)) for i in range(self.number_job)]\n",
    "\n",
    "        return state, score, done\n",
    "\n",
    "    def GenerateRandomProblem(self):\n",
    "        # Generate the jobshop problem\n",
    "        # random problem or a stable problem\n",
    "\n",
    "        if self.bool_generate_random_jssp == True:\n",
    "            a = list(range(self.time_low, self.time_high))\n",
    "            p = []\n",
    "            for k in range(self.number_job):\n",
    "                p.append(random.sample(a, self.number_machine))\n",
    "            self.M_processing_time = np.array(p)\n",
    "\n",
    "            a = list(range(self.number_machine))\n",
    "            r = []\n",
    "            for k in range(self.number_job):\n",
    "                r.append(random.sample(a, self.number_machine))\n",
    "            self.M_processing_order = np.array(r)\n",
    "\n",
    "            sum_time_of_job = np.sum(self.M_processing_time, axis=1)\n",
    "\n",
    "            for i in range(self.number_job):\n",
    "                for j in range(i+1, self.number_job):\n",
    "                    if sum_time_of_job[i] > sum_time_of_job[j]:\n",
    "                        a = np.copy(self.M_processing_time[j, :])\n",
    "                        self.M_processing_time[j,\n",
    "                                               :] = self.M_processing_time[i, :]\n",
    "                        self.M_processing_time[i, :] = a\n",
    "                        sum_time_of_job[i], sum_time_of_job[j] = sum_time_of_job[j], sum_time_of_job[i]\n",
    "\n",
    "            sum_time_of_mach = [[i, 0] for i in range(self.number_machine)]\n",
    "            for i in range(self.number_job):\n",
    "                for j in range(self.number_machine):\n",
    "                    sum_time_of_mach[self.M_processing_order[i, j]\n",
    "                                     ][1] += self.M_processing_time[i, j]\n",
    "\n",
    "            for i in range(self.number_machine):\n",
    "                for j in range(i+1, self.number_machine):\n",
    "                    if sum_time_of_mach[i][1] > sum_time_of_mach[j][1]:\n",
    "                        sum_time_of_mach[i], sum_time_of_mach[j] = sum_time_of_mach[j], sum_time_of_mach[i]\n",
    "\n",
    "            nr = np.zeros((self.number_job, self.number_machine), dtype=int)-1\n",
    "            for i in range(self.number_machine):\n",
    "                nr[self.M_processing_order == i] = sum_time_of_mach[i][0]\n",
    "\n",
    "            sum_time_of_mach = [[i, 0] for i in range(self.number_machine)]\n",
    "            for i in range(self.number_job):\n",
    "                for j in range(self.number_machine):\n",
    "                    sum_time_of_mach[self.M_processing_order[i, j]\n",
    "                                     ][1] += self.M_processing_time[i, j]\n",
    "\n",
    "            self.M_processing_order = nr\n",
    "        else:\n",
    "            self.M_processing_order = np.array(\n",
    "                [[1, 3, 0, 2], [0, 2, 1, 3], [3, 1, 2, 0], [1, 3, 0, 2], [0, 1, 2, 3]])\n",
    "            self.M_processing_time = np.array([[18, 20, 21, 17], [18, 26, 15, 16], [\n",
    "                17, 18, 27, 23], [18, 21, 25, 15], [22, 29, 28, 21]])\n",
    "\n",
    "    def MeasurementAction(self, action_history):\n",
    "        # measurement the action and return the makespan\n",
    "\n",
    "        M_start_time = np.zeros((self.number_machine, self.number_job))\n",
    "        M_end_time = np.zeros((self.number_machine, self.number_job))\n",
    "\n",
    "        timeline_machine = np.zeros((self.number_machine), dtype=int)\n",
    "        index_machine = np.zeros((self.number_machine), dtype=int)\n",
    "        timeline_job = np.zeros((self.number_job), dtype=int)\n",
    "        index_job = np.zeros((self.number_job), dtype=int)\n",
    "        X_schedule_plan = np.zeros(\n",
    "            (self.number_machine, self.number_job, 2), dtype=int)\n",
    "\n",
    "        for job_id, job_position in action_history:\n",
    "            machine_id = self.M_processing_order[job_id, job_position]\n",
    "\n",
    "            current_start_time = max(\n",
    "                timeline_machine[machine_id], timeline_job[job_id])\n",
    "            current_end_time = current_start_time + \\\n",
    "                self.M_processing_time[job_id, job_position]\n",
    "\n",
    "            timeline_machine[machine_id], timeline_job[job_id] = current_end_time, current_end_time\n",
    "            current_index = index_machine[machine_id]\n",
    "            M_start_time[machine_id, current_index] = current_start_time\n",
    "            M_end_time[machine_id, current_index] = current_end_time\n",
    "            X_schedule_plan[machine_id, current_index, :] = [\n",
    "                job_id, job_position]\n",
    "            index_machine[machine_id] += 1\n",
    "            index_job[job_id] += 1\n",
    "\n",
    "        self.M_start_time = M_start_time\n",
    "        self.M_end_time = M_end_time\n",
    "        self.X_schedule_plan = X_schedule_plan\n",
    "        return np.max(M_end_time)\n",
    "\n",
    "    def PlotResult(self, num=0):\n",
    "        # plot function for the gant map\n",
    "\n",
    "        colorbox = ['yellow', 'whitesmoke', 'lightyellow',\n",
    "                    'khaki', 'silver', 'pink', 'lightgreen', 'orange', 'grey', 'r', 'brown']\n",
    "\n",
    "        for i in range(100):\n",
    "            colorArr = ['1', '2', '3', '4', '5', '6', '7',\n",
    "                        '8', '9', 'A', 'B', 'C', 'D', 'E', 'F']\n",
    "            color = \"\"\n",
    "            for i in range(6):\n",
    "                color += colorArr[random.randint(0, 14)]\n",
    "            colorbox.append(\"#\"+color)\n",
    "\n",
    "        fig = plt.figure(figsize=(7, 4))\n",
    "        for i in range(self.number_machine):\n",
    "            # number_of_mashine:\n",
    "            for j in range(self.number_job):\n",
    "                # number_of_job:\n",
    "                # % read the start time point\n",
    "                mPoint1 = self.M_start_time[i, j]\n",
    "                mPoint2 = self.M_end_time[i, j]  # % read the end time point\n",
    "                mText = i + 1.5  # % read the index of machine\n",
    "                PlotRec(mPoint1, mPoint2, mText)  # % plot subfunction\n",
    "                Word = str(self.X_schedule_plan[i, j, 0]+1) + '.' + str(\n",
    "                    self.X_schedule_plan[i, j, 1]+1)  # % read machine id\n",
    "\n",
    "                x1, x2, x3, x4 = mPoint1, mPoint2, mPoint2, mPoint1\n",
    "                y1, y2, y3, y4 = mText-0.8, mText-0.8, mText, mText\n",
    "                plt.fill([x1, x2, x3, x4], [y1, y2, y3, y4],\n",
    "                         color=colorbox[self.X_schedule_plan[i, j, 0]])\n",
    "                plt.text(0.5*mPoint1+0.5*mPoint2-3.5, mText-0.5, Word)\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Machine')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gant.png')\n",
    "        plt.close()\n",
    "\n",
    "    def Print_info(self):\n",
    "        # print the problem infomation\n",
    "\n",
    "        print('order')\n",
    "        print(self.M_processing_order)\n",
    "        print('time')\n",
    "        print(self.M_processing_time)\n",
    "        print('start time')\n",
    "        print(self.M_start_time)\n",
    "        print('end time')\n",
    "        print(self.M_end_time)\n",
    "        print('X')\n",
    "        print(self.X_schedule_plan)\n",
    "\n",
    "    def GetFeature(self, job_id, job_position):\n",
    "        # get the feature of one position of one job \n",
    "        # readers can change the feature to get a more powerful model \n",
    "\n",
    "        # raw features\n",
    "        machine_id = self.M_processing_order[job_id, job_position]\n",
    "        job_time_need = np.sum(self.M_processing_time, axis=1)\n",
    "        current_time_use = self.M_processing_time[job_id, job_position]\n",
    "\n",
    "        machine_endtime = np.max(self.M_end_time, axis=1)\n",
    "        job_endtime = np.sum(self.M_processing_time[job_id, :job_position])\n",
    "        job_alltime = np.sum(self.M_processing_time[job_id, :])\n",
    "\n",
    "        if job_position == 0:\n",
    "            frac_currentend_othermachineave = 0.5\n",
    "            frac_currentend_otherjobave = 0.5\n",
    "            frac_currentendplusthisposition_othermachineave = 1\n",
    "            schedule_finish_station = 0\n",
    "\n",
    "            frac_jobposition_jobtime = 1\n",
    "            frac_jobposition_totaltime = 1\n",
    "        else:\n",
    "            frac_currentend_othermachineave = (\n",
    "                0.1+machine_endtime[machine_id]) / (0.1+np.average(machine_endtime))\n",
    "            frac_currentendplusthisposition_othermachineave = (\n",
    "                machine_endtime[machine_id]+current_time_use)/np.average(machine_endtime)\n",
    "            schedule_finish_station = np.count_nonzero(\n",
    "                self.M_end_time)/self.number_machine/self.number_job\n",
    "\n",
    "            frac_currentend_otherjobave = (0.1+job_endtime) / (0.1+job_alltime)\n",
    "            frac_jobposition_jobtime = current_time_use/job_time_need[job_id]\n",
    "            frac_jobposition_totaltime = current_time_use/np.sum(job_time_need)\n",
    "\n",
    "        # feature choose\n",
    "        features = []\n",
    "        # current features\n",
    "        features.append(frac_currentend_othermachineave)\n",
    "        features.append(frac_currentend_otherjobave)\n",
    "\n",
    "        # features.append(frac_currentendplusthisposition_othermachineave)\n",
    "        # features.append(schedule_finish_station)\n",
    "        # # stable features\n",
    "        # features.append(frac_jobposition_jobtime)\n",
    "        # features.append(frac_jobposition_totaltime)\n",
    "\n",
    "        self.number_features = len(features)\n",
    "\n",
    "        if job_position == -1:\n",
    "            features = [-1] * self.number_features\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "def PlotRec(mPoint1, mPoint2, mText):\n",
    "    # sub function to plot a box in figure\n",
    "\n",
    "    vPoint = np.zeros((4, 2))\n",
    "    vPoint[0, :] = [mPoint1, mText-0.8]\n",
    "    vPoint[1, :] = [mPoint2, mText-0.8]\n",
    "    vPoint[2, :] = [mPoint1, mText]\n",
    "    vPoint[3, :] = [mPoint2, mText]\n",
    "    plt.plot([vPoint[0, 0], vPoint[1, 0]], [vPoint[0, 1], vPoint[1, 1]], 'k')\n",
    "    plt.plot([vPoint[0, 0], vPoint[2, 0]], [vPoint[0, 1], vPoint[2, 1]], 'k')\n",
    "    plt.plot([vPoint[1, 0], vPoint[3, 0]], [vPoint[1, 1], vPoint[3, 1]], 'k')\n",
    "    plt.plot([vPoint[2, 0], vPoint[3, 0]], [vPoint[2, 1], vPoint[3, 1]], 'k')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # main function used in debug\n",
    "\n",
    "    problem = JobShop(4, 5, 15, 30, bool_random = False)\n",
    "    # print(problem.MeasurementAction([]))\n",
    "    #print(problem.MeasurementAction([[0, 0], [1, 0], [2, 0], [3, 0], [4, 0],[0, 1], [1, 1], [2, 1], [3, 1], [4, 1]]))\n",
    "    print(problem.Get_Possible_Job_Position())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop : 0/100,  score: 159.0 success: 0 / 10, e: 0.9\n",
      "[4, 4, 4, 4, 0, 0, 0, 0] 8\n",
      "loop : 10/100,  score: 159.0 success: 0 / 10, e: 0.9\n",
      "[4, 4, 4, 4, 0, 0, 0, 0, 3] 9\n",
      "loop : 20/100,  score: 159.0 success: 0 / 10, e: 0.9\n",
      "[4, 4, 4, 4, 0, 0, 0, 0] 8\n",
      "loop : 30/100,  score: 177.0 success: 0 / 10, e: 0.86\n",
      "[0, 0, 0, 0, 2, 2, 2, 2, 4, 4] 10\n",
      "loop : 40/100,  score: 129.0 success: 0 / 10, e: 0.82\n",
      "[0, 2, 0, 3, 0, 0, 2, 2, 1, 2] 10\n",
      "loop : 50/100,  score: 102.0 success: 0 / 10, e: 0.78\n",
      "[2, 3, 4, 3, 0, 3, 3, 0, 0] 9\n",
      "loop : 60/100,  score: 259.0 success: 0 / 10, e: 0.74\n",
      "[3, 2, 3, 3, 4, 2, 3, 4, 0, 0, 0, 0, 2, 2] 14\n",
      "loop : 70/100,  score: 111.0 success: 0 / 10, e: 0.7\n",
      "[2, 3, 2, 2, 2, 3, 3] 7\n",
      "loop : 80/100,  score: 109.0 success: 0 / 10, e: 0.67\n",
      "[2, 1, 3, 1, 2, 3, 3, 2, 4, 1, 2, 3, 0] 13\n",
      "loop : 90/100,  score: 193.0 success: 0 / 10, e: 0.64\n",
      "[2, 1, 3, 2, 3, 3, 3, 0, 4, 1, 4, 2, 2, 0, 0, 0] 16\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input,Conv1D,Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import JobShop\n",
    "\n",
    "EPISODES = 100   #tar\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    # class for deep q learning agent \n",
    "    \n",
    "    def __init__(self, state_size, action_size, number_job, number_feature):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.number_job = number_job\n",
    "        self.number_feature = number_feature\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 0.9  # exploration rate\n",
    "        self.epsilon_min = 0.001\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.0005\n",
    "        #self.model = self._build_subproblem_model() # build the model \n",
    "        self.model = self._easymodel()\n",
    "\n",
    "    def _build_subproblem_model(self):\n",
    "        # to build the whole model for jobshop  \n",
    "\n",
    "        basic_model = self._submodel()\n",
    "\n",
    "        output_list = []\n",
    "        input_list = []\n",
    "        for i in range(self.number_job):\n",
    "            input_list.append(Input(shape=(self.number_feature,)))\n",
    "            output_list.append(basic_model(input_list[i]))\n",
    "\n",
    "        concatenated = tf.keras.layers.concatenate(output_list)\n",
    "        out = Dense(self.action_size, activation='linear')(concatenated)\n",
    "        model = Model(input_list, out)\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def _submodel(self):\n",
    "        # the sub model called by function  _build_subproblem_model\n",
    "\n",
    "        model = Sequential(name='basic_model')\n",
    "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
    "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
    "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def _easymodel(self):\n",
    "        # the easy ann model, not used in this method \n",
    "        input1=Input(shape=(10,1),name=\"input_1\")\n",
    "        conv1_1=Conv1D(16,2,padding=\"same\",strides=1,activation=\"relu\")(input1)\n",
    "        flatten=Flatten()(conv1_1)\n",
    "        dense2=Dense(100,activation=\"relu\")(flatten)\n",
    "        dense=Dense(self.action_size, activation='relu')(dense2)\n",
    "        model=tf.keras.models.Model(inputs=input1,outputs=dense)\n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        # remember the information of this step\n",
    "\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        # let the agent make a decision\n",
    "        # choose a job to process in current state\n",
    "\n",
    "        if np.random.rand() >= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        # replay the history and train the model\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            history=self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        return history.history[\"loss\"]\n",
    "\n",
    "    def load(self, name):\n",
    "        # load the model\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        # save the model\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # agent.load(\"./save/jobshop-dqn.h5\")\n",
    "    number_job = 5\n",
    "    number_machine = 4\n",
    "    number_feature = 2\n",
    "    state_size = number_job * number_feature\n",
    "    action_size = number_job\n",
    "    agent = DQNAgent(state_size, action_size, number_job, number_feature)\n",
    "    batch_size = number_job * number_machine * 10\n",
    "\n",
    "    history_loss= []\n",
    "    Reward=[]\n",
    "    successnumber = 0\n",
    "    \n",
    "    Conuter=[]\n",
    "\n",
    "    # the main loop for each job shop problem \n",
    "    for e in range(EPISODES):\n",
    "        \n",
    "        problem = JobShop.JobShop(number_machine, number_job, 15, 30, False)\n",
    "        state, score, done = problem.Step()\n",
    "        #Change the state shape to satisify the input of our defined model \n",
    "        state=np.reshape(state,(1,10,1))\n",
    "        action_list = []\n",
    "        oldscore = 0\n",
    "        score = 0\n",
    "\n",
    "        # the sub loop for each step of the problem \n",
    "        for time in range(number_job*number_machine):\n",
    "\n",
    "            action = agent.act(state)\n",
    "            next_state, score, done = problem.Step(action)\n",
    "            next_state=np.reshape(next_state,(1,10,1))\n",
    "            reward = oldscore - score + 15 if not done else -1000\n",
    "            Reward.append(reward)\n",
    "            oldscore = score\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            \n",
    "        \n",
    "\n",
    "            if done:\n",
    "                if time >= number_job * number_machine-1:\n",
    "                    successnumber += 1\n",
    "                    Conuter.append([time,successnumber])\n",
    "                    \n",
    "                    problem.PlotResult()\n",
    "                    problem.Print_info()\n",
    "                break\n",
    "\n",
    "            # record the history \n",
    "            action_list.append(action)\n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            loss=agent.replay(batch_size)\n",
    "            history_loss.append(loss)\n",
    "        if e % 10 == 0:\n",
    "            print(\"loop : {}/{},  score: {} success: {} / 10, e: {:.2}\"\n",
    "                  .format(e, EPISODES, score, successnumber, agent.epsilon))\n",
    "            print(action_list, len(action_list))\n",
    "            #f = open('log/logs', 'a')\n",
    "            #f.close()\n",
    "            successnumber = 0\n",
    "\n",
    "            agent.save(\"./save/jobshop-dqn.h5\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 10, 16)            48        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               16100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 16,653\n",
      "Trainable params: 16,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(agent.model, to_file='model.png')\n",
    "agent.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_bar_x():\n",
    "    # this is for plotting purpose\n",
    "    index = np.arange(6)\n",
    "    plt.bar(index, [260,211,166,175,154,187],width=0.4,color=\"blue\",linewidth=0.5,edgecolor=\"black\")\n",
    "    plt.xlabel('Epochs', fontsize=5)\n",
    "    plt.ylabel('Make-span/mins', fontsize=5)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "plot_bar_x()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
